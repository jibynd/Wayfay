{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import simuls, utils \n",
    "from pycaret.regression import *\n",
    "importlib.reload(simuls)\n",
    "importlib.reload(utils)\n",
    "#ExampleThree = simuls.ExampleThree\n",
    "from simuls import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = ExampleOne(n = 60, sig = 1, with_test = True).data\n",
    "data.to_df()\n",
    "#data.train.to_df(); data.test.to_df()\n",
    "cols = [col for col in data.df.columns if \"x\" in col]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fast_models = [\"lr\", \"br\", \"lar\", \"llar\", \"svm\",  \"en\", \"gbr\", \"omp\", \"kr\"]\n",
    "slow_models = [\"et\", \"rf\", \"xgboost\", \"mlp\", \"tr\", ] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_df = pd.DataFrame({\"name\":my_models}).set_index(\"name\")\n",
    "res_df[[\"model\", \"mse\"]] = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tracker = []\n",
    "for model in fast_models:\n",
    "    scores = []\n",
    "    tracker += model\n",
    "    print(\"Evaluating \"+ model)\n",
    "    start = time.time(); n_iter = 100\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        data = ExampleOne(n = 60, sig=1, with_test = True, seed = i + 1).data\n",
    "        data.train.to_df(); data.test.to_df()\n",
    "        out = setup(data = data.train.df, test_data= None, target = \"y\", silent = True, remove_multicollinearity= True, \n",
    "            verbose = False, preprocess = False)\n",
    "        tuned = tune_model(create_model(model, cross_validation = False, verbose = False), optimize = \"MSE\", \n",
    "            choose_better = True, verbose = False)\n",
    "        preds = tuned.predict(data.test.df[cols]) \n",
    "        scores += [mse(preds, data.test.df[\"y\"])]\n",
    "    end = time.time() - start \n",
    "    name = get_name(tuned)\n",
    "    res_df.loc[model, [\"model\", \"mse\", \"time\"]] = [name, np.array(scores).mean(), end / n_iter]\n",
    "    print(res_df.loc[tracker,:])\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('caret': conda)"
  },
  "interpreter": {
   "hash": "3aae98d3aa184d0f9369cd41bccf387b5a6c7ce85d52a995627a41140d6e24cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}